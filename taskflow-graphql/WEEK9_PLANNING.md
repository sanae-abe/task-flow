# Week 9 Planning: Feature Expansion & Optimization

**Date**: 2025-11-09
**Status**: ðŸ“‹ Planning Phase
**Duration**: 5-7 days
**Priority**: High

---

## ðŸ“Š Executive Summary

Week 9 focuses on three key areas to enhance the TaskFlow GraphQL API:

1. **MCP Server Feature Expansion**: Add 8+ new tools and resources
2. **Performance Optimization**: Improve query performance, reduce latency, optimize bundle size
3. **Integration Test Expansion**: Achieve 90%+ test coverage with comprehensive E2E scenarios

### Goals

| Area | Current | Week 9 Target | Improvement |
|------|---------|---------------|-------------|
| **MCP Tools** | 6 tools | 10+ tools | +67% |
| **MCP Resources** | 4 resources | 8+ resources | +100% |
| **Query Performance** | Baseline | -30% latency | 30% faster |
| **Test Coverage** | ~85% | 90%+ | +5-10% |
| **E2E Scenarios** | Basic | Comprehensive | 3x scenarios |

---

## ðŸŽ¯ Part 1: MCP Server Feature Expansion

### Current State Analysis

**Existing Implementation** (Week 5-6):
```
src/mcp/
â”œâ”€â”€ tools/              # 6 tools, ~2,200 lines
â”‚   â”œâ”€â”€ task-tools.ts        # Task CRUD operations
â”‚   â”œâ”€â”€ board-tools.ts       # Board management
â”‚   â”œâ”€â”€ ai-tools.ts          # AI recommendations
â”‚   â”œâ”€â”€ webhook-tools.ts     # Webhook management
â”‚   â”œâ”€â”€ export-tools.ts      # Data export
â”‚   â””â”€â”€ template-tools.ts    # Template management
â”œâ”€â”€ resources/          # 4 resources, ~1,200 lines
â”‚   â”œâ”€â”€ task-resources.ts    # Task data resources
â”‚   â”œâ”€â”€ board-resources.ts   # Board data resources
â”‚   â”œâ”€â”€ webhook-resources.ts # Webhook data resources
â”‚   â””â”€â”€ template-resources.ts # Template data resources
â””â”€â”€ server.ts           # MCP server entry point

Total: 3,850 lines
```

**Capabilities**:
- âœ… Task CRUD (create, read, update, delete)
- âœ… Board management
- âœ… AI-powered recommendations
- âœ… Webhook configuration
- âœ… Data export (JSON, Markdown)
- âœ… Template management

**Gaps**:
- âŒ Advanced filtering & search
- âŒ Bulk operations
- âŒ Statistics & analytics
- âŒ Label management
- âŒ Subtask operations
- âŒ File attachment handling
- âŒ Recurrence management
- âŒ Batch operations

### Proposed New Tools

#### 1. **Search & Filter Tools** (Priority: High)
**File**: `src/mcp/tools/search-tools.ts` (~300 lines)

**Tools**:
- `searchTasks`: Advanced task search with filters
  - Text search (title, description)
  - Date range filters (dueDate, createdAt)
  - Status filters (todo, in_progress, done)
  - Priority filters (critical, high, medium, low)
  - Label filters
  - Board filters
- `searchTemplates`: Template search with categories
- `searchBoards`: Board search by name/description

**Why Important**: Users need advanced search capabilities for large task lists

**Implementation Estimate**: 2-3 days

#### 2. **Bulk Operations Tools** (Priority: High)
**File**: `src/mcp/tools/bulk-tools.ts` (~250 lines)

**Tools**:
- `bulkUpdateTasks`: Update multiple tasks at once
  - Batch status change
  - Batch priority change
  - Batch label assignment
  - Batch board move
- `bulkDeleteTasks`: Delete multiple tasks
- `bulkArchiveTasks`: Archive multiple tasks
- `bulkRestoreTasks`: Restore multiple deleted tasks

**Why Important**: Efficiency for managing large numbers of tasks

**Implementation Estimate**: 2 days

#### 3. **Statistics & Analytics Tools** (Priority: Medium)
**File**: `src/mcp/tools/analytics-tools.ts` (~200 lines)

**Tools**:
- `getTaskStatistics`: Overall task stats
  - Total tasks by status
  - Tasks by priority
  - Tasks by label
  - Completion rate
  - Average completion time
- `getBoardStatistics`: Board-level analytics
- `getProductivityMetrics`: User productivity insights
  - Tasks completed per day/week
  - Most productive hours
  - Task completion trends

**Why Important**: Data-driven insights for productivity improvement

**Implementation Estimate**: 2 days

#### 4. **Label Management Tools** (Priority: Medium)
**File**: `src/mcp/tools/label-tools.ts` (~150 lines)

**Tools**:
- `createLabel`: Create new label
- `updateLabel`: Update label properties
- `deleteLabel`: Delete label (with task reassignment)
- `mergLabels`: Merge multiple labels into one
- `getLabelUsageStats`: Label usage statistics

**Why Important**: Enhanced label organization and management

**Implementation Estimate**: 1-2 days

#### 5. **Subtask Management Tools** (Priority: Medium)
**File**: `src/mcp/tools/subtask-tools.ts` (~200 lines)

**Tools**:
- `createSubtask`: Add subtask to task
- `updateSubtask`: Update subtask properties
- `deleteSubtask`: Remove subtask
- `reorderSubtasks`: Change subtask order
- `toggleSubtask`: Toggle subtask completion
- `bulkUpdateSubtasks`: Batch subtask operations

**Why Important**: Complete subtask management via MCP

**Implementation Estimate**: 1-2 days

#### 6. **File Attachment Tools** (Priority: Low)
**File**: `src/mcp/tools/attachment-tools.ts` (~150 lines)

**Tools**:
- `addAttachment`: Add file to task
- `removeAttachment`: Remove file from task
- `getAttachmentInfo`: Get file metadata
- `listAttachments`: List all task attachments

**Why Important**: File management via MCP

**Implementation Estimate**: 1-2 days

#### 7. **Recurrence Management Tools** (Priority: Low)
**File**: `src/mcp/tools/recurrence-tools.ts` (~100 lines)

**Tools**:
- `setTaskRecurrence`: Configure task recurrence
- `updateRecurrencePattern`: Modify recurrence pattern
- `removeRecurrence`: Remove recurrence from task
- `getNextOccurrence`: Calculate next occurrence date

**Why Important**: Advanced recurring task management

**Implementation Estimate**: 1 day

#### 8. **Batch Import/Export Tools** (Priority: Medium)
**File**: `src/mcp/tools/batch-io-tools.ts` (~200 lines)

**Tools**:
- `importTasksFromCSV`: Bulk import from CSV
- `importTasksFromJSON`: Bulk import from JSON
- `exportToMultipleFormats`: Export to JSON, CSV, Markdown simultaneously
- `syncWithExternal`: Sync tasks with external systems

**Why Important**: Data portability and integration

**Implementation Estimate**: 2 days

### Proposed New Resources

#### 1. **Label Resources** (Priority: Medium)
**File**: `src/mcp/resources/label-resources.ts` (~150 lines)

**Resources**:
- `label://all`: List all labels
- `label://board/{boardId}`: Labels for specific board
- `label://usage-stats`: Label usage statistics

#### 2. **Statistics Resources** (Priority: Medium)
**File**: `src/mcp/resources/statistics-resources.ts` (~200 lines)

**Resources**:
- `stats://tasks`: Overall task statistics
- `stats://boards`: Board statistics
- `stats://productivity`: Productivity metrics
- `stats://trends`: Trend analysis

#### 3. **Subtask Resources** (Priority: Low)
**File**: `src/mcp/resources/subtask-resources.ts` (~100 lines)

**Resources**:
- `subtask://task/{taskId}`: Subtasks for specific task
- `subtask://all`: All subtasks across all tasks

#### 4. **Attachment Resources** (Priority: Low)
**File**: `src/mcp/resources/attachment-resources.ts` (~100 lines)

**Resources**:
- `attachment://task/{taskId}`: Attachments for specific task
- `attachment://all`: All attachments

### Implementation Priority

**Phase 1 (Days 1-3): High Priority**
1. Search & Filter Tools (2-3 days)
2. Bulk Operations Tools (2 days)

**Phase 2 (Days 4-5): Medium Priority**
3. Statistics & Analytics Tools (2 days)
4. Label Management Tools (1-2 days)
5. Subtask Management Tools (1-2 days)
6. Batch Import/Export Tools (2 days)

**Phase 3 (Days 6-7): Low Priority**
7. File Attachment Tools (1-2 days)
8. Recurrence Management Tools (1 day)

**Resources** (Parallel with tool development):
- Label Resources (Day 4)
- Statistics Resources (Day 5)
- Subtask Resources (Day 6)
- Attachment Resources (Day 7)

### Testing Strategy

**Unit Tests**:
- 15+ tests per tool file
- 10+ tests per resource file
- Edge case coverage (empty data, invalid inputs)

**Integration Tests**:
- Tool-to-resource interaction tests
- Cross-tool operation tests
- Error handling scenarios

**Expected Test Count**: +120 tests

### Documentation Updates

**New Documentation**:
1. `MCP_TOOLS_REFERENCE.md`: Complete tool reference
2. `MCP_RESOURCES_REFERENCE.md`: Complete resource reference
3. `MCP_USAGE_EXAMPLES.md`: Real-world usage examples

**Updated Documentation**:
- `MCP_SERVER_IMPLEMENTATION.md`: Add new tools/resources
- `README.md`: Update MCP capabilities list

---

## ðŸš€ Part 2: Performance Optimization

### Current Performance Baseline

**Query Performance** (Week 8):
```
GraphQL Queries:
  - getTasks: ~50-100ms (100 tasks)
  - getBoards: ~20-30ms (10 boards)
  - getTemplates: ~30-40ms (20 templates)
  - aiRecommendTasks: ~200-500ms (OpenAI API)

Redis Operations:
  - Rate limit check: ~5-10ms
  - Cache read: ~1-2ms
  - Cache write: ~2-3ms

HTTP Request Overhead:
  - Logging middleware: ~1-2ms
  - Rate limiting: ~5-10ms
  - Total middleware: ~10-15ms
```

**Resource Usage**:
- Memory: ~150MB baseline + 80MB (Week 8 features) = ~230MB
- CPU: ~5-10% idle, ~30-50% under load
- Disk I/O: Minimal (in-memory storage)

**Bundle Size** (Production):
- JavaScript: ~800KB (uncompressed), ~250KB (gzip)
- Dependencies: 18 npm packages

### Performance Goals

| Metric | Current | Target | Improvement |
|--------|---------|--------|-------------|
| **Query Latency** | 50-100ms | 35-70ms | -30% |
| **Memory Usage** | 230MB | 200MB | -13% |
| **Bundle Size** | 250KB (gzip) | 200KB (gzip) | -20% |
| **API Response Time** | 200-500ms | 150-350ms | -30% |
| **Cache Hit Ratio** | 70% | 85%+ | +15% |

### Optimization Strategies

#### 1. **Query Optimization** (Priority: High)

**Current Issues**:
- No query batching
- No caching for frequent queries
- N+1 query potential in nested resolvers

**Solutions**:

**A. Implement DataLoader Batching**
```typescript
// src/utils/dataloader.ts enhancements

// Batch task fetching
const taskLoader = new DataLoader(async (taskIds: string[]) => {
  // Single query for multiple tasks
  const tasks = await fetchTasksByIds(taskIds);
  return taskIds.map(id => tasks.find(t => t.id === id));
});

// Batch board fetching
const boardLoader = new DataLoader(async (boardIds: string[]) => {
  const boards = await fetchBoardsByIds(boardIds);
  return boardIds.map(id => boards.find(b => b.id === id));
});
```

**B. Add Query Result Caching**
```typescript
// Redis cache for frequent queries
const CACHE_TTL = {
  tasks: 5 * 60,        // 5 minutes
  boards: 10 * 60,      // 10 minutes
  templates: 15 * 60,   // 15 minutes
  statistics: 30 * 60,  // 30 minutes
};

// Cache wrapper for resolvers
async function cachedQuery<T>(
  key: string,
  fetcher: () => Promise<T>,
  ttl: number
): Promise<T> {
  const cached = await redis.get(key);
  if (cached) return JSON.parse(cached);

  const data = await fetcher();
  await redis.setex(key, ttl, JSON.stringify(data));
  return data;
}
```

**C. Optimize DataLoader Implementation**
```typescript
// Add caching to DataLoader
const taskLoader = new DataLoader(
  async (taskIds) => fetchTasksByIds(taskIds),
  { cache: true, maxBatchSize: 100 }
);
```

**Expected Improvement**: -30% query latency

**Implementation Estimate**: 2 days

#### 2. **Memory Optimization** (Priority: Medium)

**Current Issues**:
- Large dependency tree
- Potential memory leaks in long-running processes
- No memory monitoring

**Solutions**:

**A. Dependency Audit**
```bash
# Analyze bundle size
npm install -D webpack-bundle-analyzer

# Find large dependencies
npx bundle-wizard
```

**B. Memory Leak Detection**
```typescript
// src/utils/memory-monitor.ts

import v8 from 'v8';
import { logger } from './logger.js';

export function monitorMemory(intervalMs: number = 60000): void {
  setInterval(() => {
    const heapStats = v8.getHeapStatistics();
    const used = heapStats.used_heap_size / 1024 / 1024;
    const total = heapStats.total_heap_size / 1024 / 1024;
    const limit = heapStats.heap_size_limit / 1024 / 1024;

    logger.info('Memory Usage', {
      usedMB: used.toFixed(2),
      totalMB: total.toFixed(2),
      limitMB: limit.toFixed(2),
      percentUsed: ((used / limit) * 100).toFixed(2),
    });

    if (used / limit > 0.9) {
      logger.warn('High memory usage detected', { usedMB: used });
    }
  }, intervalMs);
}
```

**C. Implement Object Pooling**
```typescript
// Pool for frequently created objects
class ObjectPool<T> {
  private available: T[] = [];
  private inUse = new Set<T>();

  acquire(): T {
    const obj = this.available.pop() || this.create();
    this.inUse.add(obj);
    return obj;
  }

  release(obj: T): void {
    this.inUse.delete(obj);
    this.available.push(obj);
  }

  private create(): T {
    return {} as T; // Factory method
  }
}
```

**Expected Improvement**: -13% memory usage

**Implementation Estimate**: 1-2 days

#### 3. **Bundle Size Optimization** (Priority: Medium)

**Current Issues**:
- Large OpenAI SDK (~200KB)
- Unused code in dependencies
- No tree-shaking optimization

**Solutions**:

**A. Dependency Replacement**
```typescript
// Replace heavy dependencies with lighter alternatives

// BEFORE: openai (~200KB)
import { OpenAI } from 'openai';

// AFTER: Use fetch() directly (~0KB extra)
async function callOpenAI(prompt: string): Promise<string> {
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.AI_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: prompt }],
    }),
  });
  return (await response.json()).choices[0].message.content;
}
```

**B. Code Splitting**
```typescript
// Lazy load AI features
const aiFeatures = process.env.AI_API_ENABLED === 'true'
  ? await import('./utils/ai-client.js')
  : null;
```

**C. Tree-Shaking Configuration**
```json
// package.json
{
  "sideEffects": false,
  "type": "module"
}
```

**Expected Improvement**: -20% bundle size

**Implementation Estimate**: 1-2 days

#### 4. **Caching Strategy Enhancement** (Priority: High)

**Current Caching**:
- IP geolocation: 24-hour TTL
- Rate limiting: Sliding window
- No query result caching

**Enhanced Caching**:

**A. Multi-Tier Caching**
```typescript
// L1: In-memory (fastest, 1-5 minutes)
// L2: Redis (fast, 5-60 minutes)
// L3: Database (fallback)

class MultiTierCache<T> {
  private l1Cache = new Map<string, { data: T; expires: number }>();

  async get(key: string): Promise<T | null> {
    // L1: In-memory check
    const l1 = this.l1Cache.get(key);
    if (l1 && l1.expires > Date.now()) {
      return l1.data;
    }

    // L2: Redis check
    const l2 = await redis.get(key);
    if (l2) {
      const data = JSON.parse(l2);
      // Populate L1
      this.l1Cache.set(key, {
        data,
        expires: Date.now() + 60 * 1000, // 1 minute
      });
      return data;
    }

    return null;
  }

  async set(key: string, data: T, ttl: number): Promise<void> {
    // Set in both tiers
    this.l1Cache.set(key, {
      data,
      expires: Date.now() + Math.min(ttl, 5 * 60) * 1000,
    });
    await redis.setex(key, ttl, JSON.stringify(data));
  }
}
```

**B. Smart Cache Invalidation**
```typescript
// Invalidate related caches on mutation
async function updateTask(taskId: string, updates: Partial<Task>): Promise<Task> {
  const task = await performUpdate(taskId, updates);

  // Invalidate related caches
  await Promise.all([
    redis.del(`task:${taskId}`),
    redis.del(`tasks:board:${task.boardId}`),
    redis.del(`stats:tasks`),
  ]);

  return task;
}
```

**Expected Improvement**: +15% cache hit ratio

**Implementation Estimate**: 2 days

#### 5. **Database Query Optimization** (Priority: Low)

**Note**: Currently using in-memory storage, but preparing for future database integration.

**Preparations**:
- Index strategy design
- Query pattern analysis
- Migration plan for database

**Implementation Estimate**: 1 day (planning only)

### Performance Testing

**Tools**:
- `autocannon`: HTTP load testing
- `clinic.js`: Node.js performance profiling
- `0x`: Flamegraph profiling

**Test Scenarios**:
```bash
# Baseline performance test
autocannon -c 100 -d 30 http://localhost:4000/graphql

# Memory profiling
clinic doctor -- node dist/server.js

# CPU profiling
0x -- node dist/server.js
```

**Metrics to Track**:
- Requests per second
- Average latency (p50, p95, p99)
- Memory usage over time
- CPU usage under load
- Error rate

### Implementation Priority

**Phase 1 (Days 1-2): High Priority**
1. Query optimization (DataLoader batching)
2. Caching strategy enhancement

**Phase 2 (Days 3-4): Medium Priority**
3. Memory optimization
4. Bundle size optimization

**Phase 3 (Day 5): Low Priority**
5. Database query optimization planning

---

## ðŸ§ª Part 3: Integration Test Expansion

### Current Test Coverage

**Week 8 Status**:
```
Total Test Files: 20+
Total Tests: 100+
Pass Rate: 100%
Estimated Coverage: ~85%
```

**Coverage by Category**:
| Category | Files | Tests | Coverage |
|----------|-------|-------|----------|
| **AI Features** | 5 | 83 | 90% |
| **MCP Tools** | 6 | 50+ | 85% |
| **Infrastructure** | 9 | 50+ | 80% |

**Gaps**:
- Limited E2E scenarios
- No performance regression tests
- Missing cross-feature integration tests
- No load testing

### Test Expansion Goals

| Metric | Current | Target | Improvement |
|--------|---------|--------|-------------|
| **Test Coverage** | ~85% | 90%+ | +5-10% |
| **E2E Scenarios** | 5 | 15+ | 3x |
| **Integration Tests** | 30 | 60+ | 2x |
| **Performance Tests** | 0 | 10+ | New |

### Proposed Test Additions

#### 1. **E2E Test Scenarios** (Priority: High)

**File**: `src/__tests__/e2e/`

**Scenarios**:

**A. Complete Task Lifecycle** (`task-lifecycle.e2e.test.ts`)
```typescript
describe('Task Lifecycle E2E', () => {
  test('Create â†’ Update â†’ Complete â†’ Archive â†’ Restore â†’ Delete', async () => {
    // 1. Create task via GraphQL
    const task = await createTask({ title: 'E2E Test Task' });
    expect(task.id).toBeDefined();

    // 2. Update task via MCP tool
    const updated = await mcpClient.call('updateTask', {
      taskId: task.id,
      updates: { priority: 'high' },
    });
    expect(updated.priority).toBe('high');

    // 3. Mark complete via GraphQL mutation
    await completeTask(task.id);

    // 4. Archive task
    await archiveTask(task.id);

    // 5. Restore from archive
    await restoreTask(task.id);

    // 6. Delete permanently
    await deleteTask(task.id);

    // Verify deletion
    await expect(getTask(task.id)).rejects.toThrow();
  });
});
```

**B. AI Recommendation Flow** (`ai-recommendation.e2e.test.ts`)
```typescript
describe('AI Recommendation E2E', () => {
  test('Create tasks â†’ Get AI recommendations â†’ Accept recommendation â†’ Track completion', async () => {
    // Setup: Create 10 tasks with varying priorities
    const tasks = await createMultipleTasks(10);

    // Get AI recommendation
    const recommended = await aiRecommendTasks({ limit: 3 });
    expect(recommended.length).toBeGreaterThan(0);

    // Accept recommendation (mark in_progress)
    const task = recommended[0];
    await updateTask(task.id, { status: 'in_progress' });

    // Complete task
    await completeTask(task.id);

    // Verify AI learns from completion
    const nextRecommendation = await aiRecommendTasks({ limit: 1 });
    expect(nextRecommendation[0].id).not.toBe(task.id);
  });
});
```

**C. Webhook Integration** (`webhook-integration.e2e.test.ts`)
```typescript
describe('Webhook Integration E2E', () => {
  test('Configure webhook â†’ Trigger event â†’ Receive delivery â†’ Verify payload', async () => {
    // Setup webhook server
    const mockServer = setupMockWebhookServer();

    // Configure webhook
    const webhook = await createWebhook({
      url: mockServer.url,
      events: ['task.created', 'task.updated'],
    });

    // Trigger event (create task)
    const task = await createTask({ title: 'Webhook Test' });

    // Wait for delivery
    await waitFor(() => mockServer.requests.length > 0);

    // Verify payload
    const payload = mockServer.requests[0].body;
    expect(payload.event).toBe('task.created');
    expect(payload.data.task.id).toBe(task.id);

    mockServer.close();
  });
});
```

**D. Rate Limiting E2E** (`rate-limiting.e2e.test.ts`)
```typescript
describe('Rate Limiting E2E', () => {
  test('Exceed rate limit â†’ Receive 429 â†’ Wait â†’ Retry success', async () => {
    const client = createTestClient();

    // Make 100 requests (at limit)
    for (let i = 0; i < 100; i++) {
      const response = await client.query({ query: GET_TASKS });
      expect(response.status).toBe(200);
    }

    // 101st request should be rate limited
    await expect(client.query({ query: GET_TASKS })).rejects.toMatchObject({
      status: 429,
      message: 'Too Many Requests',
    });

    // Wait for window reset
    await sleep(60000);

    // Should succeed after reset
    const response = await client.query({ query: GET_TASKS });
    expect(response.status).toBe(200);
  });
});
```

**E. Multi-User Collaboration** (`collaboration.e2e.test.ts`)
```typescript
describe('Multi-User Collaboration E2E', () => {
  test('User A creates â†’ User B updates â†’ Both see changes', async () => {
    const userA = createAuthenticatedClient('user-a');
    const userB = createAuthenticatedClient('user-b');

    // User A creates task
    const task = await userA.createTask({ title: 'Shared Task' });

    // User B sees task
    const tasks = await userB.getTasks();
    expect(tasks.find(t => t.id === task.id)).toBeDefined();

    // User B updates task
    await userB.updateTask(task.id, { priority: 'critical' });

    // User A sees update
    const updated = await userA.getTask(task.id);
    expect(updated.priority).toBe('critical');
  });
});
```

**Implementation Estimate**: 3-4 days

#### 2. **Integration Tests** (Priority: High)

**New Integration Test Files**:

**A. GraphQL â†” MCP Integration** (`graphql-mcp.integration.test.ts`)
```typescript
describe('GraphQL â†” MCP Integration', () => {
  test('Create via GraphQL â†’ Read via MCP', async () => {
    const task = await graphqlClient.createTask({ title: 'Test' });
    const mcpTask = await mcpClient.getTool('getTask').call({ taskId: task.id });
    expect(mcpTask.title).toBe(task.title);
  });

  test('Update via MCP â†’ Read via GraphQL', async () => {
    const task = await createTask({ title: 'Test' });
    await mcpClient.getTool('updateTask').call({
      taskId: task.id,
      updates: { priority: 'high' },
    });
    const updated = await graphqlClient.getTask(task.id);
    expect(updated.priority).toBe('high');
  });
});
```

**B. AI â†” Caching Integration** (`ai-caching.integration.test.ts`)
```typescript
describe('AI â†” Caching Integration', () => {
  test('AI recommendation caching reduces OpenAI calls', async () => {
    let openaiCallCount = 0;
    jest.spyOn(openaiClient, 'chat').mockImplementation(() => {
      openaiCallCount++;
      return mockAIResponse();
    });

    // First call â†’ OpenAI API
    const rec1 = await aiRecommendTasks({ limit: 3 });
    expect(openaiCallCount).toBe(1);

    // Second call (within cache window) â†’ Cache hit
    const rec2 = await aiRecommendTasks({ limit: 3 });
    expect(openaiCallCount).toBe(1); // Still 1, not 2

    expect(rec1).toEqual(rec2);
  });
});
```

**C. Rate Limiting â†” Redis Integration** (`ratelimit-redis.integration.test.ts`)
```typescript
describe('Rate Limiting â†” Redis Integration', () => {
  test('Redis failure â†’ Fail-open behavior', async () => {
    // Simulate Redis failure
    jest.spyOn(redisClient, 'pipeline').mockImplementation(() => {
      throw new Error('Redis connection lost');
    });

    // Should still allow requests (fail-open)
    const response = await makeRequest('/graphql');
    expect(response.status).toBe(200);
  });

  test('Rate limit state persists across server restarts', async () => {
    // Make 90 requests
    for (let i = 0; i < 90; i++) {
      await makeRequest('/graphql');
    }

    // Restart server (simulated)
    await restartServer();

    // Rate limit state should persist (only 10 more allowed)
    for (let i = 0; i < 10; i++) {
      const response = await makeRequest('/graphql');
      expect(response.status).toBe(200);
    }

    // 101st should be rate limited
    await expect(makeRequest('/graphql')).rejects.toMatchObject({
      status: 429,
    });
  });
});
```

**Implementation Estimate**: 2-3 days

#### 3. **Performance Regression Tests** (Priority: Medium)

**File**: `src/__tests__/performance/`

**Tests**:

**A. Query Performance** (`query-performance.test.ts`)
```typescript
describe('Query Performance', () => {
  test('getTasks with 1000 tasks completes in <100ms', async () => {
    await createMultipleTasks(1000);

    const start = Date.now();
    await getTasks();
    const duration = Date.now() - start;

    expect(duration).toBeLessThan(100);
  });

  test('AI recommendation with 100 tasks completes in <500ms', async () => {
    await createMultipleTasks(100);

    const start = Date.now();
    await aiRecommendTasks({ limit: 5 });
    const duration = Date.now() - start;

    expect(duration).toBeLessThan(500);
  });
});
```

**B. Memory Leak Detection** (`memory-leaks.test.ts`)
```typescript
describe('Memory Leak Detection', () => {
  test('10,000 requests do not increase memory >10MB', async () => {
    const initialMemory = process.memoryUsage().heapUsed;

    for (let i = 0; i < 10000; i++) {
      await makeRequest('/graphql');
    }

    global.gc(); // Force garbage collection
    const finalMemory = process.memoryUsage().heapUsed;
    const increase = (finalMemory - initialMemory) / 1024 / 1024; // MB

    expect(increase).toBeLessThan(10);
  });
});
```

**Implementation Estimate**: 1-2 days

#### 4. **Load Testing** (Priority: Low)

**Tool**: Artillery or k6

**Scenarios**:

**A. Sustained Load** (`load-test-sustained.yml`)
```yaml
config:
  target: 'http://localhost:4000'
  phases:
    - duration: 300  # 5 minutes
      arrivalRate: 100  # 100 req/sec
scenarios:
  - name: 'GraphQL Queries'
    flow:
      - post:
          url: '/graphql'
          json:
            query: '{ tasks { id title } }'
```

**B. Spike Test** (`load-test-spike.yml`)
```yaml
config:
  target: 'http://localhost:4000'
  phases:
    - duration: 60
      arrivalRate: 10
    - duration: 10
      arrivalRate: 1000  # Spike to 1000 req/sec
    - duration: 60
      arrivalRate: 10
scenarios:
  - name: 'Spike Test'
    flow:
      - post:
          url: '/graphql'
          json:
            query: '{ tasks { id } }'
```

**Implementation Estimate**: 1 day

### Testing Infrastructure

**Tools to Add**:
```json
{
  "devDependencies": {
    "artillery": "^2.0.0",
    "k6": "^0.45.0",
    "clinic": "^13.0.0",
    "0x": "^5.0.0"
  }
}
```

**Test Scripts** (package.json):
```json
{
  "scripts": {
    "test:e2e": "vitest run src/__tests__/e2e/",
    "test:integration": "vitest run src/__tests__/integration/",
    "test:performance": "vitest run src/__tests__/performance/",
    "test:load": "artillery run load-tests/sustained.yml",
    "test:load:spike": "artillery run load-tests/spike.yml",
    "test:all": "npm run test && npm run test:e2e && npm run test:integration"
  }
}
```

### Implementation Priority

**Phase 1 (Days 1-2): High Priority**
1. E2E Test Scenarios (3-4 days)
2. Integration Tests (2-3 days)

**Phase 2 (Days 3-4): Medium Priority**
3. Performance Regression Tests (1-2 days)

**Phase 3 (Day 5): Low Priority**
4. Load Testing (1 day)

---

## ðŸ“… Week 9 Schedule

### Day 1-2: MCP Server Feature Expansion (Phase 1)
- Implement Search & Filter Tools
- Implement Bulk Operations Tools
- Write unit tests (~30 tests)

### Day 3-4: MCP Server Feature Expansion (Phase 2)
- Implement Statistics & Analytics Tools
- Implement Label Management Tools
- Implement Subtask Management Tools
- Add Label Resources
- Add Statistics Resources
- Write unit tests (~40 tests)

### Day 5: Performance Optimization (Phase 1)
- Implement DataLoader batching
- Enhance caching strategy
- Multi-tier cache implementation
- Performance benchmarking

### Day 6: Performance Optimization (Phase 2) + Testing (Phase 1)
- Memory optimization
- Bundle size optimization
- E2E test implementation (start)
- Integration test implementation (start)

### Day 7: Testing (Phase 2-3) + Documentation
- Complete E2E tests
- Complete integration tests
- Performance regression tests
- Load testing setup
- Documentation updates

---

## ðŸ“Š Success Criteria

### MCP Server Feature Expansion
- âœ… 8+ new tools implemented
- âœ… 4+ new resources implemented
- âœ… 120+ tests passing
- âœ… Documentation complete

### Performance Optimization
- âœ… -30% query latency achieved
- âœ… -13% memory usage achieved
- âœ… -20% bundle size achieved
- âœ… +15% cache hit ratio achieved

### Integration Test Expansion
- âœ… 90%+ test coverage achieved
- âœ… 15+ E2E scenarios implemented
- âœ… 60+ integration tests passing
- âœ… 10+ performance tests passing
- âœ… Load testing infrastructure ready

---

## ðŸš€ Deployment Considerations

### No Breaking Changes
All Week 9 enhancements are **backward compatible**:
- New MCP tools are additive
- Performance optimizations are transparent
- Tests do not affect production

### Optional Feature Flags
```env
# Enable new MCP tools
MCP_ADVANCED_FEATURES=true

# Enable query caching
QUERY_CACHE_ENABLED=true

# Enable performance monitoring
PERFORMANCE_MONITORING=true
```

### Monitoring & Observability
```typescript
// Enhanced logging for Week 9
logger.info('Week 9 Feature', {
  feature: 'advanced-search',
  usage: 'search-tools',
  performanceMs: duration,
});
```

---

## ðŸ“š Documentation Plan

### New Documents
1. **`MCP_TOOLS_REFERENCE.md`**: Complete MCP tools reference
2. **`MCP_RESOURCES_REFERENCE.md`**: Complete MCP resources reference
3. **`PERFORMANCE_OPTIMIZATION_REPORT.md`**: Performance improvement details
4. **`TESTING_STRATEGY.md`**: Comprehensive testing strategy

### Updated Documents
1. **`README.md`**: Add Week 9 features
2. **`PROJECT_STATUS.md`**: Update metrics
3. **`MCP_SERVER_IMPLEMENTATION.md`**: Add new tools/resources
4. **`WEEK9_COMPLETION_REPORT.md`**: Final completion report

---

## ðŸŽ¯ Risk Assessment

### Potential Risks

**1. Performance Optimization Conflicts** (Medium Risk)
- **Risk**: Caching may conflict with real-time updates
- **Mitigation**: Implement smart cache invalidation strategy

**2. Test Infrastructure Complexity** (Low Risk)
- **Risk**: E2E tests may be flaky
- **Mitigation**: Use retry logic, proper test isolation

**3. Scope Creep** (Medium Risk)
- **Risk**: Too many features may delay completion
- **Mitigation**: Stick to priority-based implementation schedule

**4. Dependency Issues** (Low Risk)
- **Risk**: New dependencies may cause conflicts
- **Mitigation**: Thorough testing, version pinning

---

## ðŸ”® Week 10 Preview

Based on Week 9 completion, Week 10 will focus on:

1. **Security Hardening**
   - Input validation improvements
   - Authentication implementation
   - Authorization framework

2. **Monitoring & Observability**
   - Metrics collection
   - Distributed tracing
   - Error tracking (Sentry)

3. **Production Deployment**
   - Docker containerization
   - CI/CD pipeline
   - Infrastructure as Code

---

**Status**: ðŸ“‹ Planning Complete
**Next Step**: Begin Week 9 implementation
**Expected Completion**: Day 46-50 (7 days from start)

---

**Generated**: 2025-11-09
**Version**: 1.0.0
**Author**: TaskFlow Development Team
